{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import glob\n",
    "import matplotlib.pyplot as plt\n",
    "import random\n",
    "\n",
    "from scipy.fftpack import fft, ifft\n",
    "from scipy import signal\n",
    "from sklearn import preprocessing\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import KFold\n",
    "\n",
    "# import features\n",
    "pd.set_option('precision', 30)\n",
    "np.set_printoptions(precision = 30)\n",
    "\n",
    "from keras.models import load_model\n",
    "from os import listdir\n",
    "from os.path import isfile, join"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = load_model('model04.hdf5')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "StandardScaler(copy=True, with_mean=True, with_std=True)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df = pd.read_csv('diff_format.csv')\n",
    "float_data=train_df.values[:,:-1]\n",
    "scaler = preprocessing.StandardScaler()\n",
    "scaler.fit(float_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "StandardScaler(copy=True, with_mean=True, with_std=True)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model.get_weights().shape\n",
    "# model.layers\n",
    "def convertdata(float_data, step_size):\n",
    "    X = float_data[:,0]\n",
    "#     y = float_data[:,1]\n",
    "    rows = X.shape[0]//step_size\n",
    "    X = X[:rows*1000]\n",
    "    X = X.reshape(rows,1000)\n",
    "#     y = [y[t] for t in range(999,len(y),1000)]\n",
    "    return X\n",
    "\n",
    "def create_FFT_feature(x, fs=4000000):\n",
    "    fft = abs(np.fft.fft(x))\n",
    "    timestep = len(x)/fs\n",
    "    freq = np.fft.fftfreq(len(x), d=timestep)\n",
    "    i = int(len(x)/2)\n",
    "    freq = freq[1:i]\n",
    "    fft = fft[1:i]    \n",
    "    ind = fft.argmax()\n",
    "    frequency = freq[ind]\n",
    "    return frequency, freq, fft\n",
    "\n",
    "def classic_sta_lta(x, length_sta, length_lta):\n",
    "    \n",
    "    sta = np.cumsum(x ** 2)\n",
    "\n",
    "    # Convert to float\n",
    "    sta = np.require(sta, dtype=np.float)\n",
    "\n",
    "    # Copy for LTA\n",
    "    lta = sta.copy()\n",
    "\n",
    "    # Compute the STA and the LTA\n",
    "    sta[length_sta:] = sta[length_sta:] - sta[:-length_sta]\n",
    "    sta /= length_sta\n",
    "    lta[length_lta:] = lta[length_lta:] - lta[:-length_lta]\n",
    "    lta /= length_lta\n",
    "\n",
    "    # Pad zeros\n",
    "#     sta[:length_lta - 1] = 0\n",
    "\n",
    "    # Avoid division by zero by setting zero values to tiny float\n",
    "    dtiny = np.finfo(0.0).tiny\n",
    "    idx = lta < dtiny\n",
    "    lta[idx] = dtiny\n",
    "\n",
    "    return (sta / lta).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_submission(model, test_path):\n",
    "    segments = [f for f in listdir(test_path) if isfile(join(test_path, f))]\n",
    "    predictions = pd.DataFrame(columns=['seg_id','time_to_failure'])\n",
    "#     print(segments)\n",
    "    for seg_id in segments:\n",
    "        file = test_path + seg_id\n",
    "        testdata = pd.read_csv(file).values\n",
    "        X_matrix = convertdata(testdata, 1000)\n",
    "#         print(X.shape)\n",
    "        X_test = np.c_[X_matrix.std(axis=1),\n",
    "                X_matrix.max(axis=1),\n",
    "                X_matrix.min(axis=1),\n",
    "                X_matrix.mean(axis=1),\n",
    "                np.apply_along_axis(create_FFT_feature, 1, X_matrix, 4000000)[:,0],\n",
    "                np.apply_along_axis(classic_sta_lta, 1, X_matrix, 10, 200)].astype(np.float)\n",
    "\n",
    "        X_test = scaler.transform(X_test)    \n",
    "#         testobj = KerasDataGenerator(testdata)\n",
    "        \n",
    "#         test_X = testobj.create_X()\n",
    "#         X.append(test_X)\n",
    "        time = model.predict(np.expand_dims(X_test,0))[0][0]\n",
    "#         print(time)\n",
    "        df = pd.DataFrame([[seg_id[:-4], time]], columns=['seg_id','time_to_failure'])\n",
    "        predictions = predictions.append(df, ignore_index=True)\n",
    "    return predictions\n",
    "\n",
    "prediction_df = create_submission(model, '../../test/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "prediction_df.to_csv('../../submissions/submission09.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.get_config()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
